{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "robust-resnet_training-robustness.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNNfakt2uyGM4T/hoa07T+g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunwoongc/robust-resnet-demo/blob/main/robust_resnet_training_robustness.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1npa3D_VbPJq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import numpy as np\n",
        "from absl import flags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBF2KnyJft6Z"
      },
      "source": [
        "sys.argv = sys.argv[:1]\n",
        "flags.DEFINE_string(\"GPU_ID\", '0', \"Specify which GPU to train the model\")\n",
        "flags.DEFINE_float(\"h\", 0.1, \"Specify the value of the step size factor h (Make h smaller, training is more stable)\")\n",
        "flags.DEFINE_integer('n', 9, \"Specify the Resisual Block number in each stack. ResNet depth = 6*n + 2\")\n",
        "flags.DEFINE_float(\"start_LR\", 0.1, \"Specify the initial learning rate for the optimizer\")\n",
        "flags.DEFINE_integer('epochs', 80, \"Specify the epochs to train the model\")\n",
        "flags.DEFINE_integer('seed', 5, \"Specify the random seed for the consistent results\")\n",
        "FLAGS = flags.FLAGS \n",
        "FLAGS(sys.argv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOYaldL5hZd2"
      },
      "source": [
        "seed_num = FLAGS.seed\n",
        "np.random.seed(seed_num)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.manual_seed(seed_num)\n",
        "torch.cuda.manual_seed_all(seed_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0TB4CrihsGt"
      },
      "source": [
        "GPU_ID = FLAGS.GPU_ID\n",
        "cuda= torch.device('cuda:' + GPU_ID)\n",
        "h = FLAGS.h\n",
        "\n",
        "n = FLAGS.n # the Resisual Block number in each stacks \n",
        "block_list = [n, n, n] # we have three stacks.\n",
        "start_LR = FLAGS.start_LR\n",
        "num_epochs = FLAGS.epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcLZbXRkhxCr"
      },
      "source": [
        "# Let us see how the hyper parameters are defined. \n",
        "print(\"\\nParameters:\")\n",
        "print(\"-\"*20)\n",
        "for attr, value in sorted(FLAGS.__flags.items()):\n",
        "    print(\"{}={}\".format(attr, value.value))\n",
        "print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAvBY-kHhxNn"
      },
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sknMDEFvhxVx"
      },
      "source": [
        "# choose the training and test datasets\n",
        "train_data = datasets.CIFAR10('./data', train=True,\n",
        "                              download=True, transform=transform_train)\n",
        "test_data = datasets.CIFAR10('./data', train=False,\n",
        "                             download=True, transform=transform_test)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXxlEcqdhxbk"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride = 1, dimension_mismatch = False):\n",
        "        \n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride= stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        \n",
        "        if dimension_mismatch:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=2, bias=False),\n",
        "                nn.BatchNorm2d(out_channel)  # Dimensionality change for inpt x\n",
        "            )            \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = self.shortcut(x) + h * out\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKzcB-o3jEdd"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, BasicBlock, num_blocks=[2, 2, 2] , num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.num_blocks = num_blocks\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        \n",
        "        \n",
        "        self.stack1 = self._make_stacks(in_channel = 16, out_channel = 16, \n",
        "                                        num_block = self.num_blocks[0], \n",
        "                                        dimension_mismatch = False)        \n",
        "        self.stack2 = self._make_stacks(in_channel = 16, out_channel = 32, \n",
        "                                        num_block = self.num_blocks[1], \n",
        "                                        dimension_mismatch = True )\n",
        "        self.stack3 = self._make_stacks(in_channel = 32, out_channel = 64, \n",
        "                                        num_block = self.num_blocks[2], \n",
        "                                        dimension_mismatch = True )\n",
        "        \n",
        "        self.linear = nn.Linear(64, num_classes)\n",
        "    \n",
        "    \n",
        "    def _make_stacks(self, in_channel = 16, out_channel = 16, num_block = 2, dimension_mismatch = False):\n",
        "        d_mismatch = dimension_mismatch\n",
        "        if dimension_mismatch == False:\n",
        "            stride = 1\n",
        "        else:\n",
        "            stride = 2\n",
        "        \n",
        "        layers = []\n",
        "        for i in range(num_block):\n",
        "            layers.append(BasicBlock(in_channel, out_channel, stride = stride, dimension_mismatch = d_mismatch ))\n",
        "            d_mismatch = False\n",
        "            stride = 1\n",
        "            in_channel = out_channel\n",
        "            \n",
        "        return(nn.Sequential(*layers))\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))        \n",
        "        out = self.stack1(out)\n",
        "        out = self.stack2(out)\n",
        "        out = self.stack3(out)\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNQj6wpKjLiq"
      },
      "source": [
        "# Model\n",
        "print('==> Building model ResNet Depth {}..'.format(2*sum(block_list) + 2))\n",
        "#torch.backends.cudnn.benchmark = True  # faster runtime\n",
        "net = ResNet(BasicBlock, num_blocks = block_list)\n",
        "net = net.to(cuda)\n",
        "#net = torch.nn.DataParallel(net) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr= start_LR, momentum=0.9)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_acc_list = []\n",
        "test_acc_list = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhfM7703jLte"
      },
      "source": [
        "def train(epoch):\n",
        "    #print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(cuda), targets.to(cuda)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        #print ( (batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "        #    % (train_loss/(batch_idx+1), 100.*correct/total, correct, total) )  )\n",
        "\n",
        "    acc = correct/total\n",
        "    print (\"###########EPOCH {} ############# Train ACC {}\".format(epoch, acc))\n",
        "    train_acc_list.append(acc)     \n",
        "        \n",
        "def test(epoch):\n",
        "    global best_test_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(cuda), targets.to(cuda)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    # Save checkpoint.\n",
        "    acc = correct/total\n",
        "    print (\"###########EPOCH {} ############# Test ACC {}\".format(epoch, acc))\n",
        "    test_acc_list.append(acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxSRa7PdjnDE"
      },
      "source": [
        "# Train\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[40,60], gamma=0.1)\n",
        "for epoch in range(num_epochs):\n",
        "    scheduler.step()\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "depth = 2*sum(block_list) + 2\n",
        "save_dir = 'vis_acc'\n",
        "name = \"seed{}depth{}epoch{}h{}start_LR{}optimzer{}\".format(seed_num,depth, num_epochs, h, start_LR,\"SGD_momentum\")\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.mkdir(save_dir)\n",
        "\n",
        "acc = dict()\n",
        "acc.update( { \"test_acc\": test_acc_list } )\n",
        "acc.update( {\"train_acc\": train_acc_list} )\n",
        "\n",
        "    \n",
        "with open(save_dir + '/' + name + \".pickle\", 'wb') as file:\n",
        "    pickle.dump(acc, file)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}